# LLM-Council

# ðŸ§™â€â™‚ï¸ LLM High Council â€” Multi-Model Round-Table Intelligence System

The **LLM High Council** is a multi-agent AI system where multiple powerful Large Language Models sit like a *round-table council*, each giving their own perspective. A final **Judge Model** evaluates all responses and produces the **best final verdict**, providing more accurate, reliable, and trustworthy reasoning.

---

## ðŸŒ€ Concept â€” Visual Round Table of Models

                   [ðŸ‘¨â€âš–ï¸ Judge Model ðŸ‘‘]
                             â–²
                             |
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ðŸ§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ðŸ§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 |                          |                               |

                   â¬‡ (Evaluates and synthesizes)
                     ðŸ‘‘ Final Verdict Sent to User


> Each AI acts as a council member. Judge compares, selects the best reasoning, and synthesizes the final answer.

---

## ðŸ“¦ Models Used


---

## ðŸ§  Backend Logic Key Code â€” FastAPI Async Multi-Model Pipeline

`backend/main.py`
```python
tasks = [controlled_fetch(model) for model in MODELS]
results = await asyncio.gather(*tasks)
verdict = await get_council_decision(client, request.prompt, results)




